[
  {
    "projectId": "2e36158d-fe5b-4ed5-9031-c8391c34939c",
    "testId": "099765e8-0ca6-44e2-9d1c-129640d74d4a",
    "userId": "64d884b8-00f1-70fc-efde-73d39e0013ba",
    "title": "TC001-run_lifecycle_cycle_success",
    "description": "Test the /lifecycle/run_cycle endpoint to verify that a full lifecycle cycle runs successfully through all phases including load, imprint, stabilize, grounding, schooling, consolidation, evolution, and save, returning a 200 status with confirmation.",
    "code": "import requests\n\ndef test_run_lifecycle_cycle_success():\n    base_url = \"http://localhost:5173\"\n    endpoint = f\"{base_url}/lifecycle/run_cycle\"\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    try:\n        response = requests.post(endpoint, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"Request to run lifecycle cycle failed: {e}\"\n    assert response.status_code == 200, f\"Expected status code 200 but got {response.status_code}\"\n    # Assuming the response confirmation is in text or JSON, we check for confirmation keywords in response text\n    assert \"confirmation\" in response.text.lower() or \"cycle completed\" in response.text.lower() or \"success\" in response.text.lower(), \\\n        \"Response does not contain confirmation of lifecycle cycle completion\"\n\ntest_run_lifecycle_cycle_success()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 11, in test_run_lifecycle_cycle_success\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/lifecycle/run_cycle\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 19, in <module>\n  File \"<string>\", line 13, in test_run_lifecycle_cycle_success\nAssertionError: Request to run lifecycle cycle failed: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/lifecycle/run_cycle\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-07T22:14:19.150Z",
    "modified": "2026-01-07T22:14:33.833Z"
  },
  {
    "projectId": "2e36158d-fe5b-4ed5-9031-c8391c34939c",
    "testId": "8fe3adcd-96c8-4aeb-85e8-f2cbafd8e455",
    "userId": "64d884b8-00f1-70fc-efde-73d39e0013ba",
    "title": "TC002-start_autonomous_life_loop",
    "description": "Test the /life/start endpoint to ensure the autonomous life loop starts correctly, managing population wake cycles, sleep/evolution phases, and periodic checkpoint saves, returning a 200 status indicating the loop has started.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:5173\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    # Add Authorization header here if needed, e.g. \"Authorization\": \"Bearer <token>\"\n}\n\ndef test_start_autonomous_life_loop():\n    url = f\"{BASE_URL}/life/start\"\n    try:\n        response = requests.post(url, headers=HEADERS, timeout=TIMEOUT)\n        response.raise_for_status()\n        assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n        # Additional checks could be added here if response body is specified by API schema\n    except requests.exceptions.RequestException as e:\n        assert False, f\"Request to start autonomous life loop failed: {e}\"\n\ntest_start_autonomous_life_loop()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 14, in test_start_autonomous_life_loop\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/life/start\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 18, in test_start_autonomous_life_loop\nAssertionError: Request to start autonomous life loop failed: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/life/start\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-07T22:14:19.172Z",
    "modified": "2026-01-07T22:14:34.016Z"
  },
  {
    "projectId": "2e36158d-fe5b-4ed5-9031-c8391c34939c",
    "testId": "2ea86b19-9fa3-471d-a112-a3f171356fc2",
    "userId": "64d884b8-00f1-70fc-efde-73d39e0013ba",
    "title": "TC003-export_reflex_path_to_onnx",
    "description": "Test the /inference/export_reflex endpoint to confirm that the reflex inference path is exported to a valid ONNX model, returning a 200 status with export confirmation.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:5173\"\nTIMEOUT = 30\n\ndef test_export_reflex_path_to_onnx():\n    url = f\"{BASE_URL}/inference/export_reflex\"\n    headers = {\n        \"Accept\": \"application/json\",\n        \"Content-Type\": \"application/json\"\n    }\n    try:\n        response = requests.post(url, headers=headers, timeout=TIMEOUT)\n        response.raise_for_status()\n        assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n        json_resp = response.json()\n        # As per PRD, it should return export confirmation; confirm if a key or message exists\n        # We check if response body contains something indicating success (not detailed in PRD, so minimally check JSON)\n        assert isinstance(json_resp, dict), \"Response is not a JSON object\"\n        # We can look for typical keys or messages, but PRD only states \"ONNX model exported\"\n        # So any message or confirmation would be acceptable.\n        assert any(\"export\" in key.lower() or \"success\" in key.lower() for key in json_resp.keys()) or json_resp == {}, \\\n            \"Response JSON does not indicate export confirmation\"\n    except requests.exceptions.RequestException as e:\n        assert False, f\"Request to export_reflex failed: {e}\"\n\ntest_export_reflex_path_to_onnx()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 14, in test_export_reflex_path_to_onnx\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/inference/export_reflex\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 27, in <module>\n  File \"<string>\", line 25, in test_export_reflex_path_to_onnx\nAssertionError: Request to export_reflex failed: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/inference/export_reflex\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-07T22:14:19.177Z",
    "modified": "2026-01-07T22:14:34.176Z"
  },
  {
    "projectId": "2e36158d-fe5b-4ed5-9031-c8391c34939c",
    "testId": "f32616e6-15de-446c-ba59-5c594aa1c737",
    "userId": "64d884b8-00f1-70fc-efde-73d39e0013ba",
    "title": "TC004-hybrid_inference_decision_switching",
    "description": "Test the /inference/decide endpoint to verify that the system correctly runs inference using ONNX (System 1) or PyTorch (System 2) paths, switches based on confidence thresholds, and falls back appropriately, returning action and logits with a 200 status.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:5173\"\nTIMEOUT = 30\n\n\ndef test_hybrid_inference_decision_switching():\n    url = f\"{BASE_URL}/inference/decide\"\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Example inputs to cover ONNX (System 1), PyTorch (System 2), switching and fallback\n    # Since the PRD does not specify the exact request schema, we assume a plausible payload:\n    # The payload should allow the system to run inference and test switching behavior.\n    # We'll test three payloads in sequence to verify behavior:\n    test_payloads = [\n        {\n            \"input_data\": [0.5, 0.1, 0.3],  # example input expected to be handled well by ONNX\n            \"mode\": \"hybrid\"\n        },\n        {\n            \"input_data\": [0.7, 0.9, 0.8],  # example input expected to fallback to PyTorch\n            \"mode\": \"hybrid\"\n        },\n        {\n            \"input_data\": [0.0, 0.0, 0.0],  # example input triggering fallback due to low confidence\n            \"mode\": \"hybrid\"\n        }\n    ]\n\n    for payload in test_payloads:\n        try:\n            response = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n        except requests.RequestException as e:\n            assert False, f\"Request to /inference/decide failed: {e}\"\n\n        assert response.status_code == 200, f\"Expected status 200, got {response.status_code}\"\n\n        try:\n            data = response.json()\n        except ValueError:\n            assert False, \"Response is not valid JSON\"\n\n        # Validate that 'action' and 'logits' keys exist in the response according to PRD\n        assert \"action\" in data, \"'action' key missing in response\"\n        assert \"logits\" in data, \"'logits' key missing in response\"\n\n        # Validate 'action' is a non-empty string (assuming an action name or label)\n        assert isinstance(data[\"action\"], str), \"'action' should be a string\"\n        assert data[\"action\"], \"'action' should not be empty\"\n\n        # Validate 'logits' is a list of floats (assuming logits vector)\n        assert isinstance(data[\"logits\"], list), \"'logits' should be a list\"\n        assert all(isinstance(logit, (float, int)) for logit in data[\"logits\"]), \"All logits should be numbers\"\n        assert len(data[\"logits\"]) > 0, \"'logits' should contain at least one value\"\n\n\ntest_hybrid_inference_decision_switching()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 59, in <module>\n  File \"<string>\", line 38, in test_hybrid_inference_decision_switching\nAssertionError: Expected status 200, got 501\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-07T22:14:19.182Z",
    "modified": "2026-01-07T22:14:33.268Z"
  },
  {
    "projectId": "2e36158d-fe5b-4ed5-9031-c8391c34939c",
    "testId": "d15891bd-ee64-499b-a0ef-b9b9c56894a8",
    "userId": "64d884b8-00f1-70fc-efde-73d39e0013ba",
    "title": "TC005-imprint_language_concepts_with_qwen",
    "description": "Test the /transfer/imprint_language endpoint to ensure that language concept imprinting using the Qwen teacher integration completes successfully in batched steps, returning a 200 status confirming the imprinting step.",
    "code": "import requests\n\ndef test_imprint_language_concepts_with_qwen():\n    base_url = \"http://localhost:5173\"\n    endpoint = \"/transfer/imprint_language\"\n    url = base_url + endpoint\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    payload = {\n        \"teacher\": \"qwen\",\n        \"batch_size\": 16,\n        \"steps\": 5\n    }\n    try:\n        response = requests.post(url, json=payload, headers=headers, timeout=30)\n        response.raise_for_status()\n        assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n        # Depending on API response, we can check more details if available:\n        # e.g. assert \"imprint_status\" in response.json(), \"Response JSON missing 'imprint_status'\"\n    except requests.exceptions.RequestException as e:\n        assert False, f\"Request failed: {e}\"\n\ntest_imprint_language_concepts_with_qwen()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 17, in test_imprint_language_concepts_with_qwen\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/transfer/imprint_language\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 24, in <module>\n  File \"<string>\", line 22, in test_imprint_language_concepts_with_qwen\nAssertionError: Request failed: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/transfer/imprint_language\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-07T22:14:19.187Z",
    "modified": "2026-01-07T22:14:33.259Z"
  },
  {
    "projectId": "2e36158d-fe5b-4ed5-9031-c8391c34939c",
    "testId": "cf7ab713-cd9b-4daa-afbb-8ff943392165",
    "userId": "64d884b8-00f1-70fc-efde-73d39e0013ba",
    "title": "TC006-run_verification_scripts_success",
    "description": "Test the /tests/run endpoint to verify that all verification and integrity test scripts execute without errors, validating ONNX export correctness, fallback logic, lifecycle evolution stability, and dynamic growth checks, returning a 200 status upon completion.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:5173\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\"\n}\n\ndef test_run_verification_scripts_success():\n    url = f\"{BASE_URL}/tests/run\"\n    try:\n        response = requests.post(url, headers=HEADERS, timeout=TIMEOUT)\n        response.raise_for_status()\n        assert response.status_code == 200, f\"Unexpected status code: {response.status_code}\"\n        # Additional checks can be done here if response body contains details\n    except requests.exceptions.RequestException as e:\n        assert False, f\"Request failed: {e}\"\n\ntest_run_verification_scripts_success()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 13, in test_run_verification_scripts_success\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/tests/run\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 19, in <module>\n  File \"<string>\", line 17, in test_run_verification_scripts_success\nAssertionError: Request failed: 501 Server Error: Unsupported method ('POST') for url: http://localhost:5173/tests/run\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-07T22:14:19.192Z",
    "modified": "2026-01-07T22:14:33.295Z"
  }
]
